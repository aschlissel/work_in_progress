{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "from odo import odo\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('art_links') as f:\n",
    "    data = f.readlines()\n",
    "    data = [data.rstrip('\\n') for data in open('art_links')]\n",
    "\n",
    "data = filter(None, data)\n",
    "data = data[12000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup_objs = []\n",
    "\n",
    "for line in data:\n",
    "    response = requests.get(line)\n",
    "    page = response.text\n",
    "    link_soup = BeautifulSoup(page)\n",
    "    soup_objs.append(link_soup)\n",
    "    \n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "client = MongoClient()\n",
    "db = client.paintings\n",
    "\n",
    "artwork_test = db.artwork_test\n",
    "\n",
    "\n",
    "for soup in soup_objs: \n",
    "    art_dict = defaultdict(list)\n",
    "    dets = soup.findAll('dt', class_='collection-details__tombstone--label')\n",
    "    for s in dets:\n",
    "        art_dict[s.text].append(s.nextSibling.nextSibling.text)\n",
    "    art_dict['title'] = soup.find('h1', class_='collection-details__object-title').encode('utf-8')\n",
    "    #art_dict['artist'] = soup.find('div',class_='collection-details__tombstone').encode('utf-8')\n",
    "    art_dict['gallery'] = soup.find('div', class_='collection-details__location').encode('utf-8')\n",
    "    art_dict['description'] = soup.find('div', class_='collection-details__label').encode('utf-8')\n",
    "    images = soup.findAll('img')\n",
    "    for i in images:\n",
    "        if 'ng-src' in str(i):\n",
    "            art_dict['image']=i.encode('utf-8')\n",
    "    artwork_test.insert_one(art_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artwork_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(artwork_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(list(artwork_test.find()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df['description'] = df['description'].str.replace('<div class=\"collection-details__label\">\\n</div>', '')\n",
    "df['description'] = df['description'].str.replace('<div class=\"collection-details__label\">\\r\\n', '')\n",
    "df['description'] = df['description'].str.replace('<br/><br/>', '')\n",
    "df['description'] = df['description'].str.replace('\\r\\n    </div>', '')\n",
    "df['gallery'] = df['gallery'].str.replace('<div class=\"collection-details__location\">\\n<svg class=\"icon\">\\n<use xlink:href=\"/dist/icons.svg#ico-marker\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\\n</svg>\\r\\n', '')\n",
    "df['gallery'] = df['gallery'].str.replace('\\r\\n    </div>', '')\n",
    "df['title'] = df['title'].str.replace('<h1 class=\"collection-details__object-title\">', '')\n",
    "df['title'] = df['title'].str.replace('</h1>', '')\n",
    "df['title'] = df['title'].str.replace('\\r\\n<br/>', '')\n",
    "#df['gallery'] = df['gallery'].str.replace('        On view at The Met Fifth Avenue in Gallery ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('my_df_1.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## NLTK With NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "About SKLearn Text Processing:\n",
    "- array: each string is an element\n",
    "- creating a feature for every word\n",
    "- vectorizer: transforms text into feature names and gives counts of each word in a vector\n",
    "- raw text to feature count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('maxent_treebank_pos_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sentences = [sent_tokenize(x.lower()) for x in df['description']]\n",
    "print sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Word Tokenziation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "words = [word_tokenize(x) for x in df['description']]\n",
    "print words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Parts of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tag import pos_tag\n",
    "word_tags = word_tokenize(df['description'].str.lower()[0])\n",
    "pos_tag(word_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blob = [TextBlob(x) for x in (df['description'])]\n",
    "blob[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Sentiment w/ TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blob[10].sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Stemming w/ TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "for word in blob[0].words:\n",
    "    print stemmer.stem(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Count Vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "About Count Vectorizer:\n",
    "- term frequency\n",
    "- converts words to a matrix of token counts\n",
    "- sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_lower = [i.lower() for i in df['description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "count_vect = vectorizer.fit_transform([i for i in df['description']])\n",
    "#count_vect = vectorizer.fit_transform(df_lower)\n",
    "count_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vect[:100].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Bigrams: break down text into two-word phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_vectorizer = CountVectorizer(stop_words= 'english', ngram_range=(2,2),min_df=1)\n",
    "bigram_vectorizer.fit_transform(df_lower[:100]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_vectorizer.get_feature_names()[200:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Term Frequency, Inverse Document Frequency:\n",
    "- a word is more important the more times it appears in a single document (high score)\n",
    "- BUT if a word appears in many documents, not a unique identifier (low score)\n",
    "- number of times a word appears in a single document / (divided by) number of documents which the word occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vect.fit_transform([i for i in df_lower[:100]]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Euclidean:\n",
    "- length of the path connecting 2 points (given by pythagorean theorum)\n",
    "- best for when data is dense or continuous  \n",
    "  \n",
    "Manhattan:\n",
    "- distance between 2 points is the sum of the absolute differences of their Cartesian coordinates(sum of the differences between x and y coordinates)\n",
    "- measured along right angles (like city blocks)  \n",
    "  \n",
    "Cosine Similarity:\n",
    "- finding cosine angle between 2 objects (normalized dot product)\n",
    "- good for sparse vectors \n",
    "- the closer to 1, the more alike\n",
    "  \n",
    "Because my matrix is sparse, I'll use cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "#text = ['hi mike', 'hi hi hi mike mike mike']\n",
    "#X = vectorizer.fit_transform(text)\n",
    "\n",
    "#print cosine_distances(X[0], X[1])\n",
    "\n",
    "#print cosine_distances()\n",
    "print cosine_distances(count_vect[2000], count_vect[80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vect[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Item-Item Collaborative Filtering:  \n",
    "- find the most similar items, then combine that in formation w/ the user's ratings for items to generate recommendations\n",
    "- will use an implicit ratings matrix (did the user like it or not?)\n",
    "- will not use explicit matrix: user ratings\n",
    "- matrix: each row is a different user, each column is a painting w/ 0 or 1\n",
    "- create a matrix w/ each painting as similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## OR SVD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
