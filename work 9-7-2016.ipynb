{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "from odo import odo\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lst = ['http://www.metmuseum.org/art/collection#!?material=Paintings&showOnly=withImage&offset=' + str(x) + '&pageSize=0&sortBy=Relevance&sortOrder=asc&perPage=20' for x in range(0, 12017, 20)]\n",
    "for i in lst:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig_links = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mini_list = lst[522:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in mini_list:\n",
    "    #page_count = 0\n",
    "    driver = webdriver.PhantomJS()\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    #driver.quit()\n",
    "    html = driver.page_source\n",
    "    soup=BeautifulSoup(html)\n",
    "    for figure in soup.find_all('figure',class_=\"card__standard-image\"):\n",
    "        #if i %20 == 0:\n",
    "            #print'killing'\n",
    "            #!killall phantomjs\n",
    "        fig = figure.find('a')['href']\n",
    "        fig_links.append(fig)\n",
    "        with open('fig_links.txt', 'a') as myfile:\n",
    "            myfile.write(fig)\n",
    "        #print 'New PAGE!'\n",
    "        #page_count += 1\n",
    "        #print page_count\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_links = []\n",
    "\n",
    "for fig in fig_links:\n",
    "    if '/art/collection/search/' in fig:\n",
    "        url = 'http://www.metmuseum.org' + fig\n",
    "        my_links.append(url)\n",
    "        with open('my_links.txt', 'a') as myfile:\n",
    "            myfile.write(url)\n",
    "        print url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(my_links)/20 + 391"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('art_links') as f:\n",
    "    data = f.readlines()\n",
    "    data = [data.rstrip('\\n') for data in open('art_links')]\n",
    "\n",
    "data = filter(None, data)\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup_objs = []\n",
    "\n",
    "for line in data:\n",
    "    response = requests.get(line)\n",
    "    page = response.text\n",
    "    link_soup = BeautifulSoup(page)\n",
    "    soup_objs.append(link_soup)\n",
    "    \n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('my_soup.txt', 'a') as myfile:\n",
    "    myfile.write(soup_objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "client = MongoClient()\n",
    "db = client.paintings\n",
    "\n",
    "artwork8 = db.artwork8\n",
    "\n",
    "\n",
    "for soup in soup_objs: \n",
    "    art_dict = defaultdict(list)\n",
    "    dets = soup.findAll('dt', class_='collection-details__tombstone--label')\n",
    "    for s in dets:\n",
    "        art_dict[s.text].append(s.nextSibling.nextSibling.text)\n",
    "    art_dict['title'] = soup.find('h1', class_='collection-details__object-title').encode('utf-8')\n",
    "    #art_dict['artist'] = soup.find('div',class_='collection-details__tombstone').encode('utf-8')\n",
    "    art_dict['gallery'] = soup.find('div', class_='collection-details__location').encode('utf-8')\n",
    "    art_dict['description'] = soup.find('div', class_='collection-details__label').encode('utf-8')\n",
    "    images = soup.findAll('img')\n",
    "    for i in images:\n",
    "        if 'ng-src' in str(i):\n",
    "            art_dict['image']=i.encode('utf-8')\n",
    "    artwork8.insert_one(art_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artwork7.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(list(artwork8.find()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('my_df.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_links(page):\n",
    "    \"\"\"given webpage get necassary links\"\"\"\n",
    "    driver = webdriver.PhantomJS()\n",
    "    driver.get(page)\n",
    "    html = driver.page_source\n",
    "    soup=BeautifulSoup(html)\n",
    "    fig_links = []\n",
    "    for figure in soup.find_all('figure',class_=\"card__standard-image\"):\n",
    "        fig = figure.find('a')['href']\n",
    "        fig_links.append(fig)\n",
    "        driver.quit()\n",
    "        \n",
    "    return fig_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_url(link):\n",
    "    \"\"\"Given the link construct a valid URL\"\"\"\n",
    "    my_links = []\n",
    "    for fig in fig_links:\n",
    "        if '/art/collection/search/' in fig:\n",
    "            url = 'http://www.metmuseum.org' + fig\n",
    "            my_links.append(url)\n",
    "    return my_links\n",
    "\n",
    "def get_data(url):\n",
    "    \"\"\"Given the url scrap required data\"\"\"\n",
    "    response = requests.get(i)\n",
    "    page = response.text\n",
    "    link_soup = BeautifulSoup(page)\n",
    "    soup_objs.append(link_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MAIN\n",
    "for page in lst:\n",
    "    links = get_links(page)\n",
    "    for i in links:\n",
    "        url = construct_url(i)\n",
    "        data = get_data(url)\n",
    "        #write data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df['description'] = df['description'].str.replace('<div class=\"collection-details__label\">\\n</div>', '')\n",
    "df['description'] = df['description'].str.replace('<div class=\"collection-details__label\">\\r\\n', '')\n",
    "df['description'] = df['description'].str.replace('<br/><br/>', '')\n",
    "df['description'] = df['description'].str.replace('\\r\\n    </div>', '')\n",
    "df['gallery'] = df['gallery'].str.replace('<div class=\"collection-details__location\">\\n<svg class=\"icon\">\\n<use xlink:href=\"/dist/icons.svg#ico-marker\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\\n</svg>\\r\\n', '')\n",
    "df['gallery'] = df['gallery'].str.replace('\\r\\n    </div>', '')\n",
    "df['title'] = df['title'].str.replace('<h1 class=\"collection-details__object-title\">', '')\n",
    "df['title'] = df['title'].str.replace('</h1>', '')\n",
    "#df['gallery'] = df['gallery'].str.replace('        On view at The Met Fifth Avenue in Gallery ', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "from odo import odo\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('art_links') as f:\n",
    "    data = f.readlines()\n",
    "    data = [data.rstrip('\\n') for data in open('art_links')]\n",
    "\n",
    "data = filter(None, data)\n",
    "data = data[1600:1800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup_objs = []\n",
    "\n",
    "for line in data:\n",
    "    response = requests.get(line)\n",
    "    page = response.text\n",
    "    link_soup = BeautifulSoup(page)\n",
    "    soup_objs.append(link_soup)\n",
    "    \n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "client = MongoClient()\n",
    "db = client.paintings\n",
    "\n",
    "artwork_test = db.artwork_test\n",
    "\n",
    "\n",
    "for soup in soup_objs: \n",
    "    art_dict = defaultdict(list)\n",
    "    dets = soup.findAll('dt', class_='collection-details__tombstone--label')\n",
    "    for s in dets:\n",
    "        art_dict[s.text].append(s.nextSibling.nextSibling.text)\n",
    "    art_dict['title'] = soup.find('h1', class_='collection-details__object-title').encode('utf-8')\n",
    "    #art_dict['artist'] = soup.find('div',class_='collection-details__tombstone').encode('utf-8')\n",
    "    art_dict['gallery'] = soup.find('div', class_='collection-details__location').encode('utf-8')\n",
    "    art_dict['description'] = soup.find('div', class_='collection-details__label').encode('utf-8')\n",
    "    images = soup.findAll('img')\n",
    "    for i in images:\n",
    "        if 'ng-src' in str(i):\n",
    "            art_dict['image']=i.encode('utf-8')\n",
    "    artwork_test.insert_one(art_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artwork_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(list(artwork_test.find()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head(500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
